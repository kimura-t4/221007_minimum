{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1655103478843,
     "user": {
      "displayName": "木村啓太",
      "userId": "07061939741693881192"
     },
     "user_tz": -540
    },
    "id": "oaC1zv7CQHzJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import PIL\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "from urllib import request\n",
    "import pathlib\n",
    "import random\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655103479788,
     "user": {
      "displayName": "木村啓太",
      "userId": "07061939741693881192"
     },
     "user_tz": -540
    },
    "id": "fFpFrota5zCT",
    "outputId": "e61022eb-5138-4127-94ad-89aa6163fe2d"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "\n",
    "seed = 3939\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1655103480082,
     "user": {
      "displayName": "木村啓太",
      "userId": "07061939741693881192"
     },
     "user_tz": -540
    },
    "id": "naaRG6u7zEcJ"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (28, 28, 1)\n",
    "LABEL_NUM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.environ[\"HOME\"] + \"/Workspace/Dataset/mnist/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpg\t\t\t   TFRecord\n",
      "png\t\t\t   train-images-idx3-ubyte.gz\n",
      "t10k-images-idx3-ubyte.gz  train-labels-idx1-ubyte.gz\n",
      "t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls $dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(x_filename, y_filename, dataset_dir):\n",
    "    x_path = dataset_dir + x_filename\n",
    "    y_path = dataset_dir + y_filename\n",
    "    with gzip.open(x_path) as fx, gzip.open(y_path) as fy:\n",
    "        fx.read(4)\n",
    "        fy.read(4)\n",
    "        N, = struct.unpack('>i', fy.read(4))\n",
    "        if N != struct.unpack('>i', fx.read(4))[0]:\n",
    "            raise RuntimeError('wrong pair of MNIST images and labels')\n",
    "        fx.read(8)\n",
    "\n",
    "        images = np.empty((N, 784), dtype=np.uint8)\n",
    "        labels = np.empty(N, dtype=np.uint8)\n",
    "\n",
    "        for i in range(N):\n",
    "            labels[i] = ord(fy.read(1))\n",
    "            for j in range(784):\n",
    "                images[i, j] = ord(fx.read(1))\n",
    "    return images.reshape(-1, *IMG_SHAPE), np.eye(LABEL_NUM)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid, y_train_valid = load_mnist(\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\", dataset_dir)\n",
    "X_test, y_test = load_mnist(\"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_proto(img, label):\n",
    "    return tf.train.Example(\n",
    "                features=tf.train.Features(\n",
    "                    feature={\n",
    "                        \"img\": tf.train.Feature(\n",
    "                            float_list=tf.train.FloatList(\n",
    "                                value=list(img.flatten())\n",
    "                            )\n",
    "                        ),\n",
    "\n",
    "                        \"img_shape\": tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(\n",
    "                                value=list(img.shape)\n",
    "                            )\n",
    "                        ),\n",
    "\n",
    "                        \"label\": tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(\n",
    "                                value=[label]\n",
    "                            )\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "feature_description = {\n",
    "    \"img\": tf.io.FixedLenFeature([28*28], tf.float32),\n",
    "    \"img_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_example_proto(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "example_proto = get_example_proto(X_train_valid[i], label=np.argmax(y_train_valid[i]))\n",
    "example_protos = [example_proto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file = 'test.tfrecords'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "  for example_proto in example_protos:\n",
    "    writer.write(example_proto.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 13:50:27.968859: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-07 13:50:28.426965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 900 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {img_shape: (None,), img: (784,), label: ()}, types: {img_shape: tf.int64, img: tf.float32, label: tf.int64}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset([record_file])\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_example_proto)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
      "  18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
      " 253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
      " 253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
      " 198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
      "  11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
      "   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
      "  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
      " 225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
      " 240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
      " 229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
      " 253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
      " 253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
      "  80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.], shape=(784,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for image_features in parsed_dataset:\n",
    "  feature = image_features['img']\n",
    "  print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPtj3TMiNQvw6yAlO3pO7E7",
   "collapsed_sections": [],
   "mount_file_id": "1Tq5z9uXmdiR2Y6FptMsUpE4ZLve8EMrq",
   "name": "cnn test mnist.ipynb",
   "provenance": [
    {
     "file_id": "1kuXp33rNbqSwLzFTbrTuX6-p6KKRW2yL",
     "timestamp": 1654850258112
    }
   ]
  },
  "interpreter": {
   "hash": "d46ce1dbe4360d4f2d5315887bc429a0b73f33913d74a70a5b0b67e0a9e45453"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
